{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.txt', header = None, sep = \";\")\n",
    "data = data[data[1]=='Johann Sebastian Bach']\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2] = data[2].str.strip('[]')\n",
    "data[2] = data[2].str.split(',')\n",
    "data[2] = data[2].apply(np.array)\n",
    "data[3] = data[2].apply(set)\n",
    "total_set = set.union(*data[3])\n",
    "pitchnames = sorted(set(item for item in total_set))\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notes = np.concatenate(data[2])\n",
    "note_counts = np.unique(all_notes, return_counts = True)[1] # Sorted by default\n",
    "weights = 1 / note_counts\n",
    "weights = weights / np.sum(weights)\n",
    "weights = -1/np.log(weights)\n",
    "weights = torch.Tensor(weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inp_out(data):\n",
    "    network_input_np = []\n",
    "    network_output_np = []\n",
    "\n",
    "    for j in tqdm(range(data.shape[0])):\n",
    "        for i in range(0, len(data[2][j]) - seq_len, 1):\n",
    "            sequence_in = data[2][j][i:i + seq_len]\n",
    "            sequence_out = data[2][j][i + seq_len]\n",
    "            network_input_np.append([note_to_int[char] for char in sequence_in])\n",
    "            network_output_np.append(note_to_int[sequence_out])\n",
    "    return network_input_np, network_output_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:24<00:00,  3.64it/s]\n"
     ]
    }
   ],
   "source": [
    "data_in, data_out = get_inp_out(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "data_in = torch.Tensor(data_in)\n",
    "data_out = torch.Tensor(data_out)\n",
    "dataset = TensorDataset(data_in, data_out)\n",
    "train_dataset, val_dataset = random_split(dataset, [int(np.ceil(len(data_in)*0.99)), int(np.floor(len(data_in)*0.01))])\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitClassifierNetwork1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.conv4 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=3)\n",
    "        self.conv5 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(32, len(pitchnames))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "        x = x.view(-1, 32)\n",
    "        x = F.dropout(x,p =0.2,training = True)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DigitClassifierNetwork1().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "criterion = nn.CrossEntropyLoss(weight = weights)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 4.03707218170166. ValLoss: 4.284275054931641. Accuracy: 4 %\n",
      "Epoch: 1. Loss: 4.128210544586182. ValLoss: 4.243627071380615. Accuracy: 4 %\n",
      "Epoch: 2. Loss: 4.281319618225098. ValLoss: 4.235813140869141. Accuracy: 4 %\n",
      "Epoch: 3. Loss: 4.379147529602051. ValLoss: 4.231405258178711. Accuracy: 3 %\n",
      "Epoch: 4. Loss: 4.216419219970703. ValLoss: 4.237486839294434. Accuracy: 4 %\n",
      "Epoch: 5. Loss: 4.376975059509277. ValLoss: 4.220913887023926. Accuracy: 4 %\n",
      "Epoch: 6. Loss: 4.326277256011963. ValLoss: 4.221240520477295. Accuracy: 4 %\n",
      "Epoch: 7. Loss: 4.323661804199219. ValLoss: 4.224662780761719. Accuracy: 3 %\n",
      "Epoch: 8. Loss: 4.0985426902771. ValLoss: 4.220141410827637. Accuracy: 3 %\n",
      "Epoch: 9. Loss: 4.242547035217285. ValLoss: 4.217456340789795. Accuracy: 3 %\n",
      "Epoch: 10. Loss: 4.198811054229736. ValLoss: 4.216111660003662. Accuracy: 4 %\n",
      "Epoch: 11. Loss: 4.266030311584473. ValLoss: 4.227846145629883. Accuracy: 4 %\n",
      "Epoch: 12. Loss: 4.290412425994873. ValLoss: 4.215940952301025. Accuracy: 4 %\n",
      "Epoch: 13. Loss: 4.153539180755615. ValLoss: 4.218390464782715. Accuracy: 4 %\n",
      "Epoch: 14. Loss: 4.377624034881592. ValLoss: 4.223107814788818. Accuracy: 3 %\n",
      "Epoch: 15. Loss: 4.136786460876465. ValLoss: 4.214680194854736. Accuracy: 4 %\n",
      "Epoch: 16. Loss: 4.355721473693848. ValLoss: 4.210391044616699. Accuracy: 4 %\n",
      "Epoch: 17. Loss: 4.383304595947266. ValLoss: 4.210939884185791. Accuracy: 4 %\n",
      "Epoch: 18. Loss: 4.004875659942627. ValLoss: 4.206424713134766. Accuracy: 4 %\n",
      "Epoch: 19. Loss: 4.205090522766113. ValLoss: 4.214308738708496. Accuracy: 4 %\n",
      "Epoch: 20. Loss: 4.192781925201416. ValLoss: 4.219606399536133. Accuracy: 3 %\n",
      "Epoch: 21. Loss: 4.203859329223633. ValLoss: 4.2110676765441895. Accuracy: 4 %\n",
      "Epoch: 22. Loss: 4.369146823883057. ValLoss: 4.206874847412109. Accuracy: 4 %\n",
      "Epoch: 23. Loss: 4.083885192871094. ValLoss: 4.20565128326416. Accuracy: 4 %\n",
      "Epoch: 24. Loss: 4.372783184051514. ValLoss: 4.22559928894043. Accuracy: 3 %\n",
      "Epoch: 25. Loss: 4.0648369789123535. ValLoss: 4.228856086730957. Accuracy: 3 %\n",
      "Epoch: 26. Loss: 4.132391452789307. ValLoss: 4.213909149169922. Accuracy: 3 %\n",
      "Epoch: 27. Loss: 4.342137336730957. ValLoss: 4.2160468101501465. Accuracy: 3 %\n",
      "Epoch: 28. Loss: 4.25368595123291. ValLoss: 4.209935188293457. Accuracy: 3 %\n",
      "Epoch: 29. Loss: 4.029466152191162. ValLoss: 4.214941501617432. Accuracy: 4 %\n",
      "Epoch: 30. Loss: 4.2515363693237305. ValLoss: 4.211962699890137. Accuracy: 3 %\n",
      "Epoch: 31. Loss: 4.139163017272949. ValLoss: 4.205610275268555. Accuracy: 4 %\n",
      "Epoch: 32. Loss: 4.170891761779785. ValLoss: 4.2053046226501465. Accuracy: 4 %\n",
      "Epoch: 33. Loss: 4.1033549308776855. ValLoss: 4.206754207611084. Accuracy: 4 %\n",
      "Epoch: 34. Loss: 4.100644588470459. ValLoss: 4.184376239776611. Accuracy: 4 %\n",
      "Epoch: 35. Loss: 4.2807936668396. ValLoss: 4.193629741668701. Accuracy: 3 %\n",
      "Epoch: 36. Loss: 4.176033973693848. ValLoss: 4.188141345977783. Accuracy: 4 %\n",
      "Epoch: 37. Loss: 4.209094047546387. ValLoss: 4.18189811706543. Accuracy: 4 %\n",
      "Epoch: 38. Loss: 4.012078285217285. ValLoss: 4.227540969848633. Accuracy: 4 %\n",
      "Epoch: 39. Loss: 4.289124488830566. ValLoss: 4.185169219970703. Accuracy: 4 %\n",
      "Epoch: 40. Loss: 4.252101421356201. ValLoss: 4.174298286437988. Accuracy: 4 %\n",
      "Epoch: 41. Loss: 4.156588554382324. ValLoss: 4.179500102996826. Accuracy: 4 %\n",
      "Epoch: 42. Loss: 4.16550350189209. ValLoss: 4.182989597320557. Accuracy: 4 %\n",
      "Epoch: 43. Loss: 4.184871196746826. ValLoss: 4.169273853302002. Accuracy: 5 %\n",
      "Epoch: 44. Loss: 4.16261100769043. ValLoss: 4.166896820068359. Accuracy: 4 %\n",
      "Epoch: 45. Loss: 3.9845709800720215. ValLoss: 4.190759658813477. Accuracy: 4 %\n",
      "Epoch: 46. Loss: 4.156428813934326. ValLoss: 4.185202598571777. Accuracy: 5 %\n",
      "Epoch: 47. Loss: 4.230188846588135. ValLoss: 4.174199104309082. Accuracy: 4 %\n",
      "Epoch: 48. Loss: 3.93768310546875. ValLoss: 4.1915507316589355. Accuracy: 4 %\n",
      "Epoch: 49. Loss: 4.140822410583496. ValLoss: 4.1769843101501465. Accuracy: 4 %\n",
      "Epoch: 50. Loss: 4.180635929107666. ValLoss: 4.175051212310791. Accuracy: 4 %\n",
      "Epoch: 51. Loss: 4.137236595153809. ValLoss: 4.173856735229492. Accuracy: 4 %\n",
      "Epoch: 52. Loss: 4.184561252593994. ValLoss: 4.161816596984863. Accuracy: 4 %\n",
      "Epoch: 53. Loss: 4.008826732635498. ValLoss: 4.1667938232421875. Accuracy: 4 %\n",
      "Epoch: 54. Loss: 4.161746501922607. ValLoss: 4.181305885314941. Accuracy: 5 %\n",
      "Epoch: 55. Loss: 4.0827412605285645. ValLoss: 4.174274921417236. Accuracy: 4 %\n",
      "Epoch: 56. Loss: 4.4183855056762695. ValLoss: 4.158920764923096. Accuracy: 3 %\n",
      "Epoch: 57. Loss: 4.406515121459961. ValLoss: 4.185878753662109. Accuracy: 4 %\n",
      "Epoch: 58. Loss: 4.205489635467529. ValLoss: 4.169879913330078. Accuracy: 4 %\n",
      "Epoch: 59. Loss: 4.130107879638672. ValLoss: 4.163949966430664. Accuracy: 4 %\n",
      "Epoch: 60. Loss: 4.213146209716797. ValLoss: 4.246951103210449. Accuracy: 4 %\n",
      "Epoch: 61. Loss: 4.157146453857422. ValLoss: 4.163781642913818. Accuracy: 4 %\n",
      "Epoch: 62. Loss: 4.114903926849365. ValLoss: 4.174712181091309. Accuracy: 4 %\n",
      "Epoch: 63. Loss: 4.128434181213379. ValLoss: 4.156938552856445. Accuracy: 4 %\n",
      "Epoch: 64. Loss: 4.1194305419921875. ValLoss: 4.17664909362793. Accuracy: 5 %\n",
      "Epoch: 65. Loss: 4.311985015869141. ValLoss: 4.186770439147949. Accuracy: 4 %\n",
      "Epoch: 66. Loss: 3.887482166290283. ValLoss: 4.185232162475586. Accuracy: 4 %\n",
      "Epoch: 67. Loss: 4.038547515869141. ValLoss: 4.165348052978516. Accuracy: 4 %\n",
      "Epoch: 68. Loss: 4.08343505859375. ValLoss: 4.180208206176758. Accuracy: 4 %\n",
      "Epoch: 69. Loss: 4.384063243865967. ValLoss: 4.229321002960205. Accuracy: 3 %\n",
      "Epoch: 70. Loss: 4.180477142333984. ValLoss: 4.174587249755859. Accuracy: 5 %\n",
      "Epoch: 71. Loss: 3.9325191974639893. ValLoss: 4.179766654968262. Accuracy: 4 %\n",
      "Epoch: 72. Loss: 4.139708042144775. ValLoss: 4.1815924644470215. Accuracy: 5 %\n",
      "Epoch: 73. Loss: 3.974916934967041. ValLoss: 4.1471734046936035. Accuracy: 4 %\n",
      "Epoch: 74. Loss: 4.059320449829102. ValLoss: 4.189284324645996. Accuracy: 4 %\n",
      "Epoch: 75. Loss: 3.957799196243286. ValLoss: 4.192210674285889. Accuracy: 5 %\n",
      "Epoch: 76. Loss: 4.2697625160217285. ValLoss: 4.191986083984375. Accuracy: 5 %\n",
      "Epoch: 77. Loss: 4.197714805603027. ValLoss: 4.184503078460693. Accuracy: 4 %\n",
      "Epoch: 78. Loss: 4.053689956665039. ValLoss: 4.176450252532959. Accuracy: 5 %\n",
      "Epoch: 79. Loss: 4.102543830871582. ValLoss: 4.2188520431518555. Accuracy: 4 %\n",
      "Epoch: 80. Loss: 4.186118125915527. ValLoss: 4.181145668029785. Accuracy: 4 %\n",
      "Epoch: 81. Loss: 4.188816070556641. ValLoss: 4.219764709472656. Accuracy: 5 %\n",
      "Epoch: 82. Loss: 4.053930282592773. ValLoss: 4.201872825622559. Accuracy: 4 %\n",
      "Epoch: 83. Loss: 4.24716854095459. ValLoss: 4.162313461303711. Accuracy: 5 %\n",
      "Epoch: 84. Loss: 4.4158935546875. ValLoss: 4.174809455871582. Accuracy: 4 %\n",
      "Epoch: 85. Loss: 4.231704235076904. ValLoss: 4.174145221710205. Accuracy: 4 %\n",
      "Epoch: 86. Loss: 4.096142292022705. ValLoss: 4.175502300262451. Accuracy: 5 %\n",
      "Epoch: 87. Loss: 4.374490261077881. ValLoss: 4.192177772521973. Accuracy: 5 %\n",
      "Epoch: 88. Loss: 4.2080607414245605. ValLoss: 4.177479267120361. Accuracy: 4 %\n",
      "Epoch: 89. Loss: 4.1806440353393555. ValLoss: 4.223532676696777. Accuracy: 5 %\n",
      "Epoch: 90. Loss: 4.146751880645752. ValLoss: 4.183781623840332. Accuracy: 5 %\n",
      "Epoch: 91. Loss: 4.199726581573486. ValLoss: 4.204469680786133. Accuracy: 4 %\n",
      "Epoch: 92. Loss: 4.213165760040283. ValLoss: 4.142850875854492. Accuracy: 4 %\n",
      "Epoch: 93. Loss: 4.019940376281738. ValLoss: 4.199895858764648. Accuracy: 5 %\n",
      "Epoch: 94. Loss: 4.174374580383301. ValLoss: 4.217720985412598. Accuracy: 4 %\n",
      "Epoch: 95. Loss: 4.221240997314453. ValLoss: 4.19760274887085. Accuracy: 4 %\n",
      "Epoch: 96. Loss: 4.150437831878662. ValLoss: 4.190441608428955. Accuracy: 4 %\n",
      "Epoch: 97. Loss: 4.021090984344482. ValLoss: 4.197628498077393. Accuracy: 4 %\n",
      "Epoch: 98. Loss: 4.242150783538818. ValLoss: 4.17837381362915. Accuracy: 4 %\n",
      "Epoch: 99. Loss: 4.028088092803955. ValLoss: 4.176906108856201. Accuracy: 4 %\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (batch_x, batch_y) in enumerate(train_data_loader):\n",
    "        # Put data in the correct device\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device).long()\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        outputs = model(batch_x.view(batch_size,1,seq_len))\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "\n",
    "        #if count % 5000 == 0:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    v_loss = 0\n",
    "\n",
    "    for val_x, val_y in val_data_loader:\n",
    "\n",
    "        # Put data in the correct device\n",
    "        val_x = val_x.to(device)\n",
    "        val_y = val_y.to(device).long()\n",
    "        # Forward pass only to get logits/output\n",
    "        with torch.no_grad():\n",
    "            output = model(val_x.view(batch_size,1, seq_len))\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        val_bloss = criterion(output, val_y)\n",
    "        v_loss += val_bloss*batch_size\n",
    "\n",
    "        # Total correct predictions\n",
    "        total += batch_size\n",
    "        correct += (predicted == val_y).sum()\n",
    "    accuracy = 100 * correct / total\n",
    "    v_loss = v_loss/total\n",
    "\n",
    "    # Print Loss\n",
    "    print('Epoch: {}. Loss: {}. ValLoss: {}. Accuracy: {} %'.format(epoch, loss.item(), v_loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 1\n",
      "torch.Size([1, 1, 100])\n",
      "count 2\n",
      "torch.Size([1, 1, 100])\n",
      "count 3\n",
      "torch.Size([1, 1, 100])\n",
      "count 4\n",
      "torch.Size([1, 1, 100])\n",
      "count 5\n",
      "torch.Size([1, 1, 100])\n",
      "count 6\n",
      "torch.Size([1, 1, 100])\n",
      "count 7\n",
      "torch.Size([1, 1, 100])\n",
      "count 8\n",
      "torch.Size([1, 1, 100])\n",
      "count 9\n",
      "torch.Size([1, 1, 100])\n",
      "count 10\n",
      "torch.Size([1, 1, 100])\n",
      "count 11\n",
      "torch.Size([1, 1, 100])\n",
      "count 12\n",
      "torch.Size([1, 1, 100])\n",
      "count 13\n",
      "torch.Size([1, 1, 100])\n",
      "count 14\n",
      "torch.Size([1, 1, 100])\n",
      "count 15\n",
      "torch.Size([1, 1, 100])\n",
      "count 16\n",
      "torch.Size([1, 1, 100])\n",
      "count 17\n",
      "torch.Size([1, 1, 100])\n",
      "count 18\n",
      "torch.Size([1, 1, 100])\n",
      "count 19\n",
      "torch.Size([1, 1, 100])\n",
      "count 20\n",
      "torch.Size([1, 1, 100])\n",
      "count 21\n",
      "torch.Size([1, 1, 100])\n",
      "count 22\n",
      "torch.Size([1, 1, 100])\n",
      "count 23\n",
      "torch.Size([1, 1, 100])\n",
      "count 24\n",
      "torch.Size([1, 1, 100])\n",
      "count 25\n",
      "torch.Size([1, 1, 100])\n",
      "count 26\n",
      "torch.Size([1, 1, 100])\n",
      "count 27\n",
      "torch.Size([1, 1, 100])\n",
      "count 28\n",
      "torch.Size([1, 1, 100])\n",
      "count 29\n",
      "torch.Size([1, 1, 100])\n",
      "count 30\n",
      "torch.Size([1, 1, 100])\n",
      "count 31\n",
      "torch.Size([1, 1, 100])\n",
      "count 32\n",
      "torch.Size([1, 1, 100])\n",
      "count 33\n",
      "torch.Size([1, 1, 100])\n",
      "count 34\n",
      "torch.Size([1, 1, 100])\n",
      "count 35\n",
      "torch.Size([1, 1, 100])\n",
      "count 36\n",
      "torch.Size([1, 1, 100])\n",
      "count 37\n",
      "torch.Size([1, 1, 100])\n",
      "count 38\n",
      "torch.Size([1, 1, 100])\n",
      "count 39\n",
      "torch.Size([1, 1, 100])\n",
      "count 40\n",
      "torch.Size([1, 1, 100])\n",
      "count 41\n",
      "torch.Size([1, 1, 100])\n",
      "count 42\n",
      "torch.Size([1, 1, 100])\n",
      "count 43\n",
      "torch.Size([1, 1, 100])\n",
      "count 44\n",
      "torch.Size([1, 1, 100])\n",
      "count 45\n",
      "torch.Size([1, 1, 100])\n",
      "count 46\n",
      "torch.Size([1, 1, 100])\n",
      "count 47\n",
      "torch.Size([1, 1, 100])\n",
      "count 48\n",
      "torch.Size([1, 1, 100])\n",
      "count 49\n",
      "torch.Size([1, 1, 100])\n",
      "count 50\n",
      "torch.Size([1, 1, 100])\n",
      "count 51\n",
      "torch.Size([1, 1, 100])\n",
      "count 52\n",
      "torch.Size([1, 1, 100])\n",
      "count 53\n",
      "torch.Size([1, 1, 100])\n",
      "count 54\n",
      "torch.Size([1, 1, 100])\n",
      "count 55\n",
      "torch.Size([1, 1, 100])\n",
      "count 56\n",
      "torch.Size([1, 1, 100])\n",
      "count 57\n",
      "torch.Size([1, 1, 100])\n",
      "count 58\n",
      "torch.Size([1, 1, 100])\n",
      "count 59\n",
      "torch.Size([1, 1, 100])\n",
      "count 60\n",
      "torch.Size([1, 1, 100])\n",
      "count 61\n",
      "torch.Size([1, 1, 100])\n",
      "count 62\n",
      "torch.Size([1, 1, 100])\n",
      "count 63\n",
      "torch.Size([1, 1, 100])\n",
      "count 64\n",
      "torch.Size([1, 1, 100])\n",
      "count 65\n",
      "torch.Size([1, 1, 100])\n",
      "count 66\n",
      "torch.Size([1, 1, 100])\n",
      "count 67\n",
      "torch.Size([1, 1, 100])\n",
      "count 68\n",
      "torch.Size([1, 1, 100])\n",
      "count 69\n",
      "torch.Size([1, 1, 100])\n",
      "count 70\n",
      "torch.Size([1, 1, 100])\n",
      "count 71\n",
      "torch.Size([1, 1, 100])\n",
      "count 72\n",
      "torch.Size([1, 1, 100])\n",
      "count 73\n",
      "torch.Size([1, 1, 100])\n",
      "count 74\n",
      "torch.Size([1, 1, 100])\n",
      "count 75\n",
      "torch.Size([1, 1, 100])\n",
      "count 76\n",
      "torch.Size([1, 1, 100])\n",
      "count 77\n",
      "torch.Size([1, 1, 100])\n",
      "count 78\n",
      "torch.Size([1, 1, 100])\n",
      "count 79\n",
      "torch.Size([1, 1, 100])\n",
      "count 80\n",
      "torch.Size([1, 1, 100])\n",
      "count 81\n",
      "torch.Size([1, 1, 100])\n",
      "count 82\n",
      "torch.Size([1, 1, 100])\n",
      "count 83\n",
      "torch.Size([1, 1, 100])\n",
      "count 84\n",
      "torch.Size([1, 1, 100])\n",
      "count 85\n",
      "torch.Size([1, 1, 100])\n",
      "count 86\n",
      "torch.Size([1, 1, 100])\n",
      "count 87\n",
      "torch.Size([1, 1, 100])\n",
      "count 88\n",
      "torch.Size([1, 1, 100])\n",
      "count 89\n",
      "torch.Size([1, 1, 100])\n",
      "count 90\n",
      "torch.Size([1, 1, 100])\n",
      "count 91\n",
      "torch.Size([1, 1, 100])\n",
      "count 92\n",
      "torch.Size([1, 1, 100])\n",
      "count 93\n",
      "torch.Size([1, 1, 100])\n",
      "count 94\n",
      "torch.Size([1, 1, 100])\n",
      "count 95\n",
      "torch.Size([1, 1, 100])\n",
      "count 96\n",
      "torch.Size([1, 1, 100])\n",
      "count 97\n",
      "torch.Size([1, 1, 100])\n",
      "count 98\n",
      "torch.Size([1, 1, 100])\n",
      "count 99\n",
      "torch.Size([1, 1, 100])\n",
      "count 100\n",
      "torch.Size([1, 1, 100])\n",
      "count 101\n",
      "torch.Size([1, 1, 100])\n",
      "count 102\n",
      "torch.Size([1, 1, 100])\n",
      "count 103\n",
      "torch.Size([1, 1, 100])\n",
      "count 104\n",
      "torch.Size([1, 1, 100])\n",
      "count 105\n",
      "torch.Size([1, 1, 100])\n",
      "count 106\n",
      "torch.Size([1, 1, 100])\n",
      "count 107\n",
      "torch.Size([1, 1, 100])\n",
      "count 108\n",
      "torch.Size([1, 1, 100])\n",
      "count 109\n",
      "torch.Size([1, 1, 100])\n",
      "count 110\n",
      "torch.Size([1, 1, 100])\n",
      "count 111\n",
      "torch.Size([1, 1, 100])\n",
      "count 112\n",
      "torch.Size([1, 1, 100])\n",
      "count 113\n",
      "torch.Size([1, 1, 100])\n",
      "count 114\n",
      "torch.Size([1, 1, 100])\n",
      "count 115\n",
      "torch.Size([1, 1, 100])\n",
      "count 116\n",
      "torch.Size([1, 1, 100])\n",
      "count 117\n",
      "torch.Size([1, 1, 100])\n",
      "count 118\n",
      "torch.Size([1, 1, 100])\n",
      "count 119\n",
      "torch.Size([1, 1, 100])\n",
      "count 120\n",
      "torch.Size([1, 1, 100])\n",
      "count 121\n",
      "torch.Size([1, 1, 100])\n",
      "count 122\n",
      "torch.Size([1, 1, 100])\n",
      "count 123\n",
      "torch.Size([1, 1, 100])\n",
      "count 124\n",
      "torch.Size([1, 1, 100])\n",
      "count 125\n",
      "torch.Size([1, 1, 100])\n",
      "count 126\n",
      "torch.Size([1, 1, 100])\n",
      "count 127\n",
      "torch.Size([1, 1, 100])\n",
      "count 128\n",
      "torch.Size([1, 1, 100])\n",
      "count 129\n",
      "torch.Size([1, 1, 100])\n",
      "count 130\n",
      "torch.Size([1, 1, 100])\n",
      "count 131\n",
      "torch.Size([1, 1, 100])\n",
      "count 132\n",
      "torch.Size([1, 1, 100])\n",
      "count 133\n",
      "torch.Size([1, 1, 100])\n",
      "count 134\n",
      "torch.Size([1, 1, 100])\n",
      "count 135\n",
      "torch.Size([1, 1, 100])\n",
      "count 136\n",
      "torch.Size([1, 1, 100])\n",
      "count 137\n",
      "torch.Size([1, 1, 100])\n",
      "count 138\n",
      "torch.Size([1, 1, 100])\n",
      "count 139\n",
      "torch.Size([1, 1, 100])\n",
      "count 140\n",
      "torch.Size([1, 1, 100])\n",
      "count 141\n",
      "torch.Size([1, 1, 100])\n",
      "count 142\n",
      "torch.Size([1, 1, 100])\n",
      "count 143\n",
      "torch.Size([1, 1, 100])\n",
      "count 144\n",
      "torch.Size([1, 1, 100])\n",
      "count 145\n",
      "torch.Size([1, 1, 100])\n",
      "count 146\n",
      "torch.Size([1, 1, 100])\n",
      "count 147\n",
      "torch.Size([1, 1, 100])\n",
      "count 148\n",
      "torch.Size([1, 1, 100])\n",
      "count 149\n",
      "torch.Size([1, 1, 100])\n",
      "count 150\n",
      "torch.Size([1, 1, 100])\n",
      "count 151\n",
      "torch.Size([1, 1, 100])\n",
      "count 152\n",
      "torch.Size([1, 1, 100])\n",
      "count 153\n",
      "torch.Size([1, 1, 100])\n",
      "count 154\n",
      "torch.Size([1, 1, 100])\n",
      "count 155\n",
      "torch.Size([1, 1, 100])\n",
      "count 156\n",
      "torch.Size([1, 1, 100])\n",
      "count 157\n",
      "torch.Size([1, 1, 100])\n",
      "count 158\n",
      "torch.Size([1, 1, 100])\n",
      "count 159\n",
      "torch.Size([1, 1, 100])\n",
      "count 160\n",
      "torch.Size([1, 1, 100])\n",
      "count 161\n",
      "torch.Size([1, 1, 100])\n",
      "count 162\n",
      "torch.Size([1, 1, 100])\n",
      "count 163\n",
      "torch.Size([1, 1, 100])\n",
      "count 164\n",
      "torch.Size([1, 1, 100])\n",
      "count 165\n",
      "torch.Size([1, 1, 100])\n",
      "count 166\n",
      "torch.Size([1, 1, 100])\n",
      "count 167\n",
      "torch.Size([1, 1, 100])\n",
      "count 168\n",
      "torch.Size([1, 1, 100])\n",
      "count 169\n",
      "torch.Size([1, 1, 100])\n",
      "count 170\n",
      "torch.Size([1, 1, 100])\n",
      "count 171\n",
      "torch.Size([1, 1, 100])\n",
      "count 172\n",
      "torch.Size([1, 1, 100])\n",
      "count 173\n",
      "torch.Size([1, 1, 100])\n",
      "count 174\n",
      "torch.Size([1, 1, 100])\n",
      "count 175\n",
      "torch.Size([1, 1, 100])\n",
      "count 176\n",
      "torch.Size([1, 1, 100])\n",
      "count 177\n",
      "torch.Size([1, 1, 100])\n",
      "count 178\n",
      "torch.Size([1, 1, 100])\n",
      "count 179\n",
      "torch.Size([1, 1, 100])\n",
      "count 180\n",
      "torch.Size([1, 1, 100])\n",
      "count 181\n",
      "torch.Size([1, 1, 100])\n",
      "count 182\n",
      "torch.Size([1, 1, 100])\n",
      "count 183\n",
      "torch.Size([1, 1, 100])\n",
      "count 184\n",
      "torch.Size([1, 1, 100])\n",
      "count 185\n",
      "torch.Size([1, 1, 100])\n",
      "count 186\n",
      "torch.Size([1, 1, 100])\n",
      "count 187\n",
      "torch.Size([1, 1, 100])\n",
      "count 188\n",
      "torch.Size([1, 1, 100])\n",
      "count 189\n",
      "torch.Size([1, 1, 100])\n",
      "count 190\n",
      "torch.Size([1, 1, 100])\n",
      "count 191\n",
      "torch.Size([1, 1, 100])\n",
      "count 192\n",
      "torch.Size([1, 1, 100])\n",
      "count 193\n",
      "torch.Size([1, 1, 100])\n",
      "count 194\n",
      "torch.Size([1, 1, 100])\n",
      "count 195\n",
      "torch.Size([1, 1, 100])\n",
      "count 196\n",
      "torch.Size([1, 1, 100])\n",
      "count 197\n",
      "torch.Size([1, 1, 100])\n",
      "count 198\n",
      "torch.Size([1, 1, 100])\n",
      "count 199\n",
      "torch.Size([1, 1, 100])\n",
      "count 200\n",
      "torch.Size([1, 1, 100])\n"
     ]
    }
   ],
   "source": [
    "pred_len = 200\n",
    "count = 0\n",
    "seq = [note_to_int[note] for note in data[2][0][:100]]\n",
    "seq = torch.Tensor(seq).view(1,1,100).to(device)\n",
    "prediction = []\n",
    "for i in range(pred_len):\n",
    "    count+=1\n",
    "        new_note = model(seq)\n",
    "    _, new_note = torch.max(new_note, 1)\n",
    "    seq = torch.cat((seq, new_note.view(1,1,1).float()), 2)[:, :, 1:]\n",
    "    new_note = new_note.cpu().numpy()\n",
    "    prediction.append(new_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('train.txt', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_len = 200\n",
    "seq1 = val_dataset[2][0]\n",
    "seq = seq1.view(1,1,100).to(device)\n",
    "prediction = []\n",
    "for i in range(pred_len):\n",
    "    with torch.no_grad():\n",
    "        new_note = model(seq)\n",
    "    _, new_note = torch.max(new_note, 1)\n",
    "    seq = torch.cat((seq, new_note.view(1,1,1).float()), 2)[:, :, 1:]\n",
    "    new_note = new_note.cpu().numpy()\n",
    "    prediction.append(new_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('val.txt', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train = np.loadtxt('train.txt')\n",
    "predicted_val = np.loadtxt('val.txt')\n",
    "predicted_train = [int_to_note[note] for note in predicted_train]\n",
    "predicted_val = [int_to_note[note] for note in predicted_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "output_notes = []\n",
    "# create note and chord objects based on the values generated by the model\n",
    "for pattern in predicted_val:\n",
    "    # pattern is a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    # pattern is a note\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "    # increase offset each iteration so that notes do not stack\n",
    "    offset += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val_2.mid'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp = \"val_2.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
