{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from music21 import note, chord, instrument, stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.txt', header = None, sep = \";\")\n",
    "data = data[data[1]=='Johann Sebastian Bach']\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2] = data[2].str.strip('[]')\n",
    "data[2] = data[2].str.split(',')\n",
    "data[2] = data[2].apply(np.array)\n",
    "data[3] = data[2].apply(set)\n",
    "total_set = set.union(*data[3])\n",
    "pitchnames = sorted(set(item for item in total_set))\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notes = np.concatenate(data[2])\n",
    "note_counts = np.unique(all_notes, return_counts = True)[1] # Sorted by default\n",
    "weights = 1 / note_counts\n",
    "weights = weights / np.sum(weights)\n",
    "weights = -1/np.log(weights)\n",
    "weights = torch.Tensor(weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inp_out(data):\n",
    "    network_input_np = []\n",
    "    network_output_np = []\n",
    "\n",
    "    for j in tqdm(range(data.shape[0])):\n",
    "        for i in range(0, len(data[2][j]) - seq_len, 1):\n",
    "            sequence_in = data[2][j][i:i + seq_len]\n",
    "            sequence_out = data[2][j][i + seq_len]\n",
    "            network_input_np.append([note_to_int[char] for char in sequence_in])\n",
    "            network_output_np.append(note_to_int[sequence_out])\n",
    "    return network_input_np, network_output_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 89/89 [00:21<00:00,  2.98it/s]\n"
     ]
    }
   ],
   "source": [
    "data_in, data_out = get_inp_out(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "data_in = torch.Tensor(data_in)\n",
    "data_out = torch.Tensor(data_out)\n",
    "dataset = TensorDataset(data_in, data_out)\n",
    "train_dataset, val_dataset = random_split(dataset, [int(np.ceil(len(data_in)*0.99)), int(np.floor(len(data_in)*0.01))])\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Building your LSTM\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True, dropout = 0.2)\n",
    "        \n",
    "        #####self.lstm2 = nn.LSTM(hidden_dim, hidden_dim2, layer_dim2, batch_first=True)\n",
    "        # Readout layer\n",
    "        self.fc0 = nn.Linear(hidden_dim, 256)\n",
    "        self.drop = nn.Dropout(p = 0.3)\n",
    "        self.fc1 = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "\n",
    "        # 28 time steps\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc0(out[:, -1, :])\n",
    "        out = self.drop(out)\n",
    "        out = self.fc1(out)\n",
    "        # out.size() --> 100, 10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMModel(1, 256, 3, len(pitchnames)).to(device)\n",
    "model.load_state_dict(torch.load('model_1', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "criterion = nn.CrossEntropyLoss(weight = weights)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 4.424532413482666. ValLoss: 4.216208457946777. Accuracy: 3 %\n",
      "Epoch: 1. Loss: 4.255472660064697. ValLoss: 4.1815643310546875. Accuracy: 3 %\n",
      "Epoch: 2. Loss: 4.010770320892334. ValLoss: 4.147602558135986. Accuracy: 4 %\n",
      "Epoch: 3. Loss: 4.128831386566162. ValLoss: 4.150794982910156. Accuracy: 4 %\n",
      "Epoch: 4. Loss: 3.879819631576538. ValLoss: 4.07977819442749. Accuracy: 5 %\n",
      "Epoch: 5. Loss: 3.9912993907928467. ValLoss: 4.053655624389648. Accuracy: 5 %\n",
      "Epoch: 6. Loss: 3.784130334854126. ValLoss: 3.986482620239258. Accuracy: 7 %\n",
      "Epoch: 7. Loss: 3.7824018001556396. ValLoss: 3.972188949584961. Accuracy: 6 %\n",
      "Epoch: 8. Loss: 3.980056047439575. ValLoss: 3.949808120727539. Accuracy: 7 %\n",
      "Epoch: 9. Loss: 3.8413937091827393. ValLoss: 3.9255802631378174. Accuracy: 6 %\n",
      "Epoch: 10. Loss: 3.570657253265381. ValLoss: 3.9147305488586426. Accuracy: 7 %\n",
      "Epoch: 11. Loss: 3.6698853969573975. ValLoss: 3.8973217010498047. Accuracy: 8 %\n",
      "Epoch: 12. Loss: 3.650193214416504. ValLoss: 3.8238728046417236. Accuracy: 8 %\n",
      "Epoch: 13. Loss: 3.576854705810547. ValLoss: 3.815091609954834. Accuracy: 8 %\n",
      "Epoch: 14. Loss: 3.6221768856048584. ValLoss: 3.808453321456909. Accuracy: 8 %\n",
      "Epoch: 15. Loss: 3.68061900138855. ValLoss: 3.7616662979125977. Accuracy: 9 %\n",
      "Epoch: 16. Loss: 3.376539707183838. ValLoss: 3.7218334674835205. Accuracy: 10 %\n",
      "Epoch: 17. Loss: 3.4594192504882812. ValLoss: 3.7357895374298096. Accuracy: 10 %\n",
      "Epoch: 18. Loss: 3.8353769779205322. ValLoss: 3.690073013305664. Accuracy: 11 %\n",
      "Epoch: 19. Loss: 3.3448662757873535. ValLoss: 3.720463752746582. Accuracy: 11 %\n",
      "Epoch: 20. Loss: 3.4552934169769287. ValLoss: 3.7233669757843018. Accuracy: 11 %\n",
      "Epoch: 21. Loss: 3.313948392868042. ValLoss: 3.665637969970703. Accuracy: 13 %\n",
      "Epoch: 22. Loss: 3.3807671070098877. ValLoss: 3.721205234527588. Accuracy: 11 %\n",
      "Epoch: 23. Loss: 3.0391805171966553. ValLoss: 3.6784698963165283. Accuracy: 12 %\n",
      "Epoch: 24. Loss: 3.059670925140381. ValLoss: 3.6809375286102295. Accuracy: 12 %\n",
      "Epoch: 25. Loss: 3.1418848037719727. ValLoss: 3.729222059249878. Accuracy: 12 %\n",
      "Epoch: 26. Loss: 3.1474335193634033. ValLoss: 3.7043919563293457. Accuracy: 13 %\n",
      "Epoch: 27. Loss: 3.130641222000122. ValLoss: 3.6993184089660645. Accuracy: 12 %\n",
      "Epoch: 28. Loss: 3.0806524753570557. ValLoss: 3.7180750370025635. Accuracy: 12 %\n",
      "Epoch: 29. Loss: 3.150001049041748. ValLoss: 3.6818785667419434. Accuracy: 13 %\n",
      "Epoch: 30. Loss: 2.834608554840088. ValLoss: 3.7124016284942627. Accuracy: 12 %\n",
      "Epoch: 31. Loss: 3.008265972137451. ValLoss: 3.7059314250946045. Accuracy: 12 %\n",
      "Epoch: 32. Loss: 3.0607824325561523. ValLoss: 3.700270175933838. Accuracy: 14 %\n",
      "Epoch: 33. Loss: 2.9682767391204834. ValLoss: 3.6792023181915283. Accuracy: 13 %\n",
      "Epoch: 34. Loss: 3.017648458480835. ValLoss: 3.6959240436553955. Accuracy: 13 %\n",
      "Epoch: 35. Loss: 2.924140214920044. ValLoss: 3.684030532836914. Accuracy: 13 %\n",
      "Epoch: 36. Loss: 3.044532299041748. ValLoss: 3.7504799365997314. Accuracy: 13 %\n",
      "Epoch: 37. Loss: 2.8035354614257812. ValLoss: 3.7494189739227295. Accuracy: 12 %\n",
      "Epoch: 38. Loss: 2.6610705852508545. ValLoss: 3.7869319915771484. Accuracy: 13 %\n",
      "Epoch: 39. Loss: 3.097031354904175. ValLoss: 3.7472026348114014. Accuracy: 14 %\n",
      "Epoch: 40. Loss: 2.879608631134033. ValLoss: 3.7515909671783447. Accuracy: 13 %\n",
      "Epoch: 41. Loss: 2.8492043018341064. ValLoss: 3.739844560623169. Accuracy: 14 %\n",
      "Epoch: 42. Loss: 2.694913148880005. ValLoss: 3.749497890472412. Accuracy: 14 %\n",
      "Epoch: 43. Loss: 2.6979987621307373. ValLoss: 3.782198667526245. Accuracy: 13 %\n",
      "Epoch: 44. Loss: 2.7111918926239014. ValLoss: 3.8103721141815186. Accuracy: 12 %\n",
      "Epoch: 45. Loss: 2.8064751625061035. ValLoss: 3.8364620208740234. Accuracy: 13 %\n",
      "Epoch: 46. Loss: 2.796095371246338. ValLoss: 3.7977797985076904. Accuracy: 13 %\n",
      "Epoch: 47. Loss: 2.9275524616241455. ValLoss: 3.8133749961853027. Accuracy: 13 %\n",
      "Epoch: 48. Loss: 3.0458409786224365. ValLoss: 3.8044538497924805. Accuracy: 14 %\n",
      "Epoch: 49. Loss: 2.6009294986724854. ValLoss: 3.855226993560791. Accuracy: 13 %\n",
      "Epoch: 50. Loss: 2.908830404281616. ValLoss: 3.8247385025024414. Accuracy: 14 %\n",
      "Epoch: 51. Loss: 2.4697866439819336. ValLoss: 3.877324342727661. Accuracy: 13 %\n",
      "Epoch: 52. Loss: 2.9780192375183105. ValLoss: 3.8864033222198486. Accuracy: 12 %\n",
      "Epoch: 53. Loss: 2.8491108417510986. ValLoss: 3.8863139152526855. Accuracy: 13 %\n",
      "Epoch: 54. Loss: 2.7655725479125977. ValLoss: 3.8506267070770264. Accuracy: 14 %\n",
      "Epoch: 55. Loss: 2.683122396469116. ValLoss: 3.8756000995635986. Accuracy: 14 %\n",
      "Epoch: 56. Loss: 2.8352067470550537. ValLoss: 3.8648743629455566. Accuracy: 14 %\n",
      "Epoch: 57. Loss: 2.6194658279418945. ValLoss: 3.9006500244140625. Accuracy: 13 %\n",
      "Epoch: 58. Loss: 2.614633083343506. ValLoss: 3.906128406524658. Accuracy: 15 %\n",
      "Epoch: 59. Loss: 2.80315899848938. ValLoss: 3.896723985671997. Accuracy: 13 %\n",
      "Epoch: 60. Loss: 2.8378820419311523. ValLoss: 3.904738664627075. Accuracy: 14 %\n",
      "Epoch: 61. Loss: 2.6568069458007812. ValLoss: 3.8919413089752197. Accuracy: 14 %\n",
      "Epoch: 62. Loss: 2.937354803085327. ValLoss: 3.9445462226867676. Accuracy: 13 %\n",
      "Epoch: 63. Loss: 2.7567780017852783. ValLoss: 3.9081060886383057. Accuracy: 15 %\n",
      "Epoch: 64. Loss: 2.9044008255004883. ValLoss: 3.9342799186706543. Accuracy: 14 %\n",
      "Epoch: 65. Loss: 2.6103789806365967. ValLoss: 3.9653844833374023. Accuracy: 14 %\n",
      "Epoch: 66. Loss: 2.4936442375183105. ValLoss: 3.9310288429260254. Accuracy: 15 %\n",
      "Epoch: 67. Loss: 2.7574894428253174. ValLoss: 3.9710612297058105. Accuracy: 14 %\n",
      "Epoch: 68. Loss: 2.666330099105835. ValLoss: 3.937403440475464. Accuracy: 13 %\n",
      "Epoch: 69. Loss: 2.44555926322937. ValLoss: 3.939727306365967. Accuracy: 14 %\n",
      "Epoch: 70. Loss: 2.5891222953796387. ValLoss: 3.9954395294189453. Accuracy: 15 %\n",
      "Epoch: 71. Loss: 2.251194477081299. ValLoss: 3.997437000274658. Accuracy: 13 %\n",
      "Epoch: 72. Loss: 2.7422854900360107. ValLoss: 4.033501148223877. Accuracy: 13 %\n",
      "Epoch: 73. Loss: 2.412904977798462. ValLoss: 3.981177568435669. Accuracy: 14 %\n",
      "Epoch: 74. Loss: 2.582303047180176. ValLoss: 3.9715046882629395. Accuracy: 13 %\n",
      "Epoch: 75. Loss: 2.408554792404175. ValLoss: 3.9776320457458496. Accuracy: 15 %\n",
      "Epoch: 76. Loss: 2.3021492958068848. ValLoss: 4.060466289520264. Accuracy: 15 %\n",
      "Epoch: 77. Loss: 2.554856061935425. ValLoss: 3.987065076828003. Accuracy: 15 %\n",
      "Epoch: 78. Loss: 2.476713180541992. ValLoss: 3.996856689453125. Accuracy: 16 %\n",
      "Epoch: 79. Loss: 2.7513368129730225. ValLoss: 4.00869083404541. Accuracy: 14 %\n",
      "Epoch: 80. Loss: 2.3949828147888184. ValLoss: 3.9897122383117676. Accuracy: 15 %\n",
      "Epoch: 81. Loss: 2.3201849460601807. ValLoss: 4.052128791809082. Accuracy: 15 %\n",
      "Epoch: 82. Loss: 2.6075680255889893. ValLoss: 4.025716304779053. Accuracy: 14 %\n",
      "Epoch: 83. Loss: 2.277862310409546. ValLoss: 4.0996198654174805. Accuracy: 14 %\n",
      "Epoch: 84. Loss: 2.4595024585723877. ValLoss: 4.042001724243164. Accuracy: 15 %\n",
      "Epoch: 85. Loss: 2.6133859157562256. ValLoss: 4.112913131713867. Accuracy: 14 %\n",
      "Epoch: 86. Loss: 2.3170387744903564. ValLoss: 4.106856822967529. Accuracy: 15 %\n",
      "Epoch: 87. Loss: 2.292588233947754. ValLoss: 4.0867085456848145. Accuracy: 15 %\n",
      "Epoch: 88. Loss: 2.7046499252319336. ValLoss: 4.141287803649902. Accuracy: 14 %\n",
      "Epoch: 89. Loss: 2.188124656677246. ValLoss: 4.105557441711426. Accuracy: 14 %\n",
      "Epoch: 90. Loss: 2.4225411415100098. ValLoss: 4.052652359008789. Accuracy: 14 %\n",
      "Epoch: 91. Loss: 2.411700963973999. ValLoss: 4.066332817077637. Accuracy: 14 %\n",
      "Epoch: 92. Loss: 2.323477268218994. ValLoss: 4.159937858581543. Accuracy: 14 %\n",
      "Epoch: 93. Loss: 2.3111047744750977. ValLoss: 4.105905055999756. Accuracy: 14 %\n",
      "Epoch: 94. Loss: 2.2892749309539795. ValLoss: 4.0974578857421875. Accuracy: 15 %\n",
      "Epoch: 95. Loss: 2.556619882583618. ValLoss: 4.070365905761719. Accuracy: 15 %\n",
      "Epoch: 96. Loss: 2.2848734855651855. ValLoss: 4.093257427215576. Accuracy: 15 %\n",
      "Epoch: 97. Loss: 2.295977830886841. ValLoss: 4.077423095703125. Accuracy: 15 %\n",
      "Epoch: 98. Loss: 2.3890490531921387. ValLoss: 4.141648769378662. Accuracy: 14 %\n",
      "Epoch: 99. Loss: 2.276311159133911. ValLoss: 4.178420066833496. Accuracy: 15 %\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (batch_x, batch_y) in enumerate(train_data_loader):\n",
    "\n",
    "        # Put data in the correct device\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device).long()\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        outputs = model(batch_x.view(batch_size, seq_len, 1))\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "\n",
    "        #if count % 5000 == 0:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    v_loss = 0\n",
    "\n",
    "    for val_x, val_y in val_data_loader:\n",
    "\n",
    "        # Put data in the correct device\n",
    "        val_x = val_x.to(device)\n",
    "        val_y = val_y.to(device).long()\n",
    "        # Forward pass only to get logits/output\n",
    "        with torch.no_grad():\n",
    "            output = model(val_x.view(batch_size, seq_len, 1))\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        val_bloss = criterion(output, val_y)\n",
    "        v_loss += val_bloss*batch_size\n",
    "\n",
    "        # Total correct predictions\n",
    "        total += batch_size\n",
    "        correct += (predicted == val_y).sum()\n",
    "    accuracy = 100 * correct / total\n",
    "    v_loss = v_loss/total\n",
    "\n",
    "    # Print Loss\n",
    "    print('Epoch: {}. Loss: {}. ValLoss: {}. Accuracy: {} %'.format(epoch, loss.item(), v_loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_len = 200\n",
    "seq = [note_to_int[note] for note in data[2][0][:100]]\n",
    "seq = torch.Tensor(seq).view(1,100,1).to(device)\n",
    "prediction = []\n",
    "for i in range(pred_len):\n",
    "    with torch.no_grad():\n",
    "        new_note = model(seq)\n",
    "    _, new_note = torch.max(new_note, 1)\n",
    "    seq = torch.cat((seq, new_note.view(1,1,1).float()), 1)[:, 1:,:]\n",
    "    new_note = new_note.cpu().numpy()\n",
    "    prediction.append(new_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('train.txt', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_len = 200\n",
    "seq1 = val_dataset[2][0]\n",
    "seq = seq1.view(1,100,1).to(device)\n",
    "prediction = []\n",
    "for i in range(pred_len):\n",
    "    with torch.no_grad():\n",
    "        new_note = model(seq)\n",
    "    _, new_note = torch.max(new_note, 1)\n",
    "    seq = torch.cat((seq, new_note.view(1,1,1).float()), 1)[:,1:,:]\n",
    "    new_note = new_note.cpu().numpy()\n",
    "    prediction.append(new_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('val.txt', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train = np.loadtxt('train.txt')\n",
    "predicted_val = np.loadtxt('val.txt')\n",
    "predicted_train = [int_to_note[note] for note in predicted_train]\n",
    "predicted_val = [int_to_note[note] for note in predicted_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "output_notes = []\n",
    "# create note and chord objects based on the values generated by the model\n",
    "for pattern in predicted_val:\n",
    "    # pattern is a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    # pattern is a note\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "    # increase offset each iteration so that notes do not stack\n",
    "    offset += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val_3.mid'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp = \"val_3.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
