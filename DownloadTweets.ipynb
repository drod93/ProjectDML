{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import itertools\n",
    "import pickle\n",
    "import tweepy\n",
    "import os\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Developer keys here\n",
    "# It is CENSORED\n",
    "consumer_key = '6lHzfwWqyBwNFHxie482abHMq'\n",
    "consumer_key_secret = 'yOCeN6avx75tawuhMIBFNrakmZgyDJCDTEhZMn28HP8o0rJKOF'\n",
    "access_token = '24066585-MOzN32VLtggsBpfTVGUh0UBetVZXGfWF2qG1lF1vc'\n",
    "access_token_secret = 'ypsm3RFeq0cOXhnK9fEIq0TxRYcgSayshz17DvjRBQuPb'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method creates the training set\n",
    "def createTrainingSet(corpusFile, targetResultFile):\n",
    "    import csv\n",
    "    import time\n",
    "\n",
    "    counter = 0\n",
    "    corpus = []\n",
    "\n",
    "    with open(corpusFile, 'r') as csvfile:\n",
    "        lineReader = csv.reader(csvfile, delimiter=',', quotechar=\"\\\"\")\n",
    "        for row in lineReader:\n",
    "            corpus.append({\"tweet_id\": row[0], \"label\": row[1]})\n",
    "\n",
    "    sleepTime = 2\n",
    "    trainingDataSet = []\n",
    "\n",
    "    \n",
    "    for tweet in zip(*[iter(corpus)]*100):\n",
    "        list_ids = [t[\"tweet_id\"] for t in tweet]\n",
    "        try:\n",
    "            tweetFetched = api.statuses_lookup(list_ids)\n",
    "            for tw in tweetFetched:\n",
    "                for one in tweet:\n",
    "                    if one['tweet_id']== str(tw.id):\n",
    "                        lb = one['label']\n",
    "                trainingDataSet.append({'tweet_id':tw.id, 'text':tw.text,'label':lb})\n",
    "            time.sleep(sleepTime)\n",
    "      \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    with io.open(targetResultFile, 'w+',encoding=\"utf-8\") as csvfile:\n",
    "        linewriter = csv.writer(csvfile, delimiter=',', quotechar=\"\\\"\")\n",
    "        for tweet in trainingDataSet:\n",
    "            try:\n",
    "                linewriter.writerow([tweet[\"tweet_id\"], tweet[\"text\"],tweet[\"label\"]])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "    return trainingDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code starts here\n",
    "# This is corpus dataset\n",
    "corpusFile = \"NAACL_SRW_2016.csv\"\n",
    "# This is my target file\n",
    "targetResultFile = \"targetResultFile.csv\"\n",
    "# Call the method\n",
    "resultFile = createTrainingSet(corpusFile, targetResultFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
